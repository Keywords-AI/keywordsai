# KeywordsAI OpenTelemetry Implementation Guide

This document explains the new direct OpenTelemetry implementation that replaces the Traceloop SDK dependency.

## üéØ Overview

The new implementation provides the same functionality as Traceloop but with direct OpenTelemetry usage, offering better control, performance, and maintainability.

## üèóÔ∏è Architecture

### Core Components

```
src/keywordsai_tracing/
‚îú‚îÄ‚îÄ core/                    # Core OpenTelemetry implementation
‚îÇ   ‚îú‚îÄ‚îÄ tracer.py           # Main tracer class (replaces Traceloop)
‚îÇ   ‚îú‚îÄ‚îÄ processor.py        # Custom span processor for metadata
‚îÇ   ‚îî‚îÄ‚îÄ exporter.py         # KeywordsAI-specific OTLP exporter
‚îú‚îÄ‚îÄ decorators/             # Function/class decorators
‚îÇ   ‚îú‚îÄ‚îÄ base.py            # Base decorator implementation
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py        # Workflow, task, agent, tool decorators
‚îú‚îÄ‚îÄ contexts/              # Context managers
‚îÇ   ‚îî‚îÄ‚îÄ span.py           # Span attribute context manager
‚îú‚îÄ‚îÄ utils/                 # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ notebook.py       # Notebook detection
‚îÇ   ‚îî‚îÄ‚îÄ instrumentation.py # Library instrumentation
‚îú‚îÄ‚îÄ instruments.py         # Instrumentation enum
‚îî‚îÄ‚îÄ main.py               # Main KeywordsAITelemetry class
```

## üîÑ Migration from Traceloop

### Before (with Traceloop)
```python
from keywordsai_tracing import KeywordsAITelemetry
from traceloop.sdk import Traceloop

# Traceloop was initialized internally
k_tl = KeywordsAITelemetry()
```

### After (Direct OpenTelemetry)
```python
from keywordsai_tracing import KeywordsAITelemetry

# Same interface, but now uses direct OpenTelemetry
k_tl = KeywordsAITelemetry()
```

**No code changes required!** The API remains the same.

## üßµ Threading and Concurrency

### How Traceloop Handled Threading
- Used `ThreadingInstrumentor().instrument()` for context propagation
- Singleton pattern with thread-safe initialization
- BatchSpanProcessor for production, SimpleSpanProcessor for notebooks

### Our Implementation
```python
class KeywordsAITracer:
    _instance = None
    _lock = Lock()
    
    def __new__(cls, *args, **kwargs):
        """Thread-safe singleton pattern"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def _setup_threading(self):
        """Setup threading instrumentation for context propagation"""
        ThreadingInstrumentor().instrument()
```

### Key Threading Features
1. **Thread-safe singleton**: Only one tracer instance across all threads
2. **Context propagation**: OpenTelemetry context flows across thread boundaries
3. **Batch processing**: Background thread handles span export without blocking
4. **Graceful shutdown**: Proper cleanup on application exit

## üìä Span Processing Pipeline

### 1. Span Creation
```python
def _setup_span(entity_name: str, span_kind: str, version: Optional[int] = None):
    """Setup OpenTelemetry span and context"""
    tracer = KeywordsAITracer().get_tracer()
    span = tracer.start_span(f"{entity_name}.{span_kind}")
    
    # Set KeywordsAI-specific attributes
    span.set_attribute(SpanAttributes.TRACELOOP_SPAN_KIND, tlp_span_kind.value)
    span.set_attribute(SpanAttributes.TRACELOOP_ENTITY_NAME, entity_name)
```

### 2. Metadata Injection
```python
class KeywordsAISpanProcessor:
    def on_start(self, span, parent_context):
        """Add KeywordsAI metadata to spans"""
        # Add workflow name, entity path, trace group ID, etc.
        workflow_name = context_api.get_value("keywordsai_workflow_name")
        if workflow_name:
            span.set_attribute(SpanAttributes.TRACELOOP_WORKFLOW_NAME, workflow_name)
```

### 3. Export to KeywordsAI
```python
class KeywordsAISpanExporter:
    def __init__(self, endpoint, api_key, headers):
        # Build proper OTLP endpoint
        traces_endpoint = self._build_traces_endpoint(endpoint)
        
        # Initialize OTLP exporter with auth
        self.exporter = OTLPSpanExporter(
            endpoint=traces_endpoint,
            headers={"Authorization": f"Bearer {api_key}", **headers}
        )
```

## üéõÔ∏è Instrumentation Management

### Dynamic Library Detection
```python
def _init_openai() -> bool:
    """Initialize OpenAI instrumentation"""
    if not is_package_installed("openai"):
        return False
    
    try:
        from opentelemetry.instrumentation.openai import OpenAIInstrumentor
        instrumentor = OpenAIInstrumentor()
        if not instrumentor.is_instrumented_by_opentelemetry:
            instrumentor.instrument()
        return True
    except Exception as e:
        logging.error(f"Failed to initialize OpenAI instrumentation: {e}")
        return False
```

### Supported Libraries
- **AI/ML**: OpenAI, Anthropic, Cohere, Mistral, Ollama, Groq, etc.
- **Cloud AI**: AWS Bedrock, Google Vertex AI, IBM Watson X
- **Vector DBs**: Pinecone, Qdrant, Chroma, Milvus, Weaviate
- **Frameworks**: LangChain, LlamaIndex, Haystack, CrewAI
- **Infrastructure**: Redis, Requests, urllib3, PyMySQL

## üé® Decorator Implementation

### Unified Async/Sync Support
```python
def _create_entity_method_decorator(name, version, span_kind):
    def decorator(fn):
        if _is_async_method(fn):
            if inspect.isasyncgenfunction(fn):
                # Handle async generators
                @wraps(fn)
                async def async_gen_wrapper(*args, **kwargs):
                    span, ctx_token = _setup_span(entity_name, span_kind, version)
                    try:
                        result = fn(*args, **kwargs)
                        async for item in _ahandle_generator(span, ctx_token, result):
                            yield item
                    except Exception as e:
                        span.record_exception(e)
                        raise
                return async_gen_wrapper
            else:
                # Handle regular async functions
                @wraps(fn)
                async def async_wrapper(*args, **kwargs):
                    span, ctx_token = _setup_span(entity_name, span_kind, version)
                    try:
                        result = await fn(*args, **kwargs)
                        return result
                    finally:
                        _cleanup_span(span, ctx_token)
                return async_wrapper
        else:
            # Handle sync functions and generators
            @wraps(fn)
            def sync_wrapper(*args, **kwargs):
                span, ctx_token = _setup_span(entity_name, span_kind, version)
                try:
                    result = fn(*args, **kwargs)
                    if inspect.isgeneratorfunction(fn):
                        return _handle_generator(span, ctx_token, result)
                    else:
                        return result
                finally:
                    if not inspect.isgeneratorfunction(fn):
                        _cleanup_span(span, ctx_token)
            return sync_wrapper
    return decorator
```

## üîß Configuration Options

### Environment Variables
```bash
KEYWORDSAI_API_KEY=your-api-key
KEYWORDSAI_BASE_URL=https://api.keywordsai.co/api
KEYWORDSAI_DISABLE_BATCH=false
```

### Programmatic Configuration
```python
from keywordsai_tracing import KeywordsAITelemetry, Instruments

telemetry = KeywordsAITelemetry(
    app_name="my-app",
    api_key="your-key",
    base_url="https://api.keywordsai.co/api",
    disable_batch=False,
    instruments={Instruments.OPENAI, Instruments.ANTHROPIC},
    block_instruments={Instruments.REDIS, Instruments.REQUESTS},
    resource_attributes={"service.version": "1.0.0"},
    enabled=True
)
```

## üöÄ Performance Improvements

### 1. Reduced Dependencies
- **Before**: Traceloop SDK + its dependencies
- **After**: Direct OpenTelemetry (already required)

### 2. Better Batch Processing
```python
# Choose processor based on environment
if disable_batch or is_notebook():
    processor = SimpleSpanProcessor(exporter)  # Immediate export
else:
    processor = BatchSpanProcessor(exporter)   # Batched export
```

### 3. Efficient Context Management
```python
@contextmanager
def keywordsai_span_attributes(**kwargs):
    """Efficient context value management"""
    tokens = []
    for key, value in context_values.items():
        token = context_api.attach(context_api.set_value(key, value))
        tokens.append(token)
    
    try:
        yield
    finally:
        for token in reversed(tokens):
            context_api.detach(token)
```

## üß™ Testing

Run the test script to verify the implementation:

```bash
python test_new_implementation.py
```

### Test Coverage
- ‚úÖ Basic initialization
- ‚úÖ Workflow and task decorators
- ‚úÖ Context manager functionality
- ‚úÖ Async/await support
- ‚úÖ Error handling and exception recording
- ‚úÖ Mock library integration

## üîç Debugging

### Enable Debug Logging
```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Now you'll see detailed OpenTelemetry logs
telemetry = KeywordsAITelemetry()
```

### Verify Spans are Created
```python
from opentelemetry import trace

@workflow(name="debug_workflow")
def debug_workflow():
    current_span = trace.get_current_span()
    print(f"Current span: {current_span}")
    print(f"Span context: {current_span.get_span_context()}")
```

## üìà Benefits Over Traceloop

1. **Direct Control**: No wrapper layer, direct OpenTelemetry usage
2. **Better Performance**: Reduced overhead, optimized batch processing
3. **Cleaner Dependencies**: Fewer external dependencies
4. **Enhanced Debugging**: Better error messages and logging
5. **Future-Proof**: Direct OpenTelemetry ensures compatibility
6. **Thread Safety**: Improved concurrent execution handling
7. **Async Support**: Native async/await and generator support

## üîÑ Backward Compatibility

The new implementation maintains 100% API compatibility:

```python
# All existing code continues to work unchanged
from keywordsai_tracing import KeywordsAITelemetry, workflow, task
from keywordsai_tracing.contexts.span import keywordsai_span_attributes

k_tl = KeywordsAITelemetry()

@workflow(name="my_workflow")
def my_workflow():
    with keywordsai_span_attributes(
        keywordsai_params={"trace_group_identifier": "test"}
    ):
        # Your existing code here
        pass
```

## üéØ Next Steps

1. **Test thoroughly** with your existing codebase
2. **Monitor performance** improvements
3. **Remove Traceloop dependency** from requirements
4. **Update documentation** to reflect the new implementation
5. **Consider additional OpenTelemetry features** now available

The new implementation provides a solid foundation for future enhancements while maintaining the familiar KeywordsAI API. 