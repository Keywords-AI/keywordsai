{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Keywords AI Experiments Workflow Demo\n",
    "\n",
    "This notebook demonstrates the complete workflow for managing experiments in Keywords AI, including creation, adding test cases and model configurations, running experiments, and evaluating results.\n",
    "\n",
    "## What are Experiments in Keywords AI?\n",
    "\n",
    "Keywords AI experiments are powerful tools for A/B testing different AI model configurations and prompts. They allow you to:\n",
    "\n",
    "- **Compare multiple model configurations** (columns) across the same test cases\n",
    "- **Test different prompts, temperatures, and parameters** systematically  \n",
    "- **Run evaluations** to automatically score and compare results\n",
    "- **Analyze performance** across different scenarios\n",
    "- **Make data-driven decisions** about which configurations work best\n",
    "\n",
    "Each experiment consists of:\n",
    "- **Columns**: Different model configurations (prompts, models, parameters)\n",
    "- **Rows**: Test cases with inputs and optional expected outputs\n",
    "- **Results**: Generated outputs from running each column against each row\n",
    "- **Evaluations**: Automated scoring of the results\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Keywords AI API key (`KEYWORDSAI_API_KEY`)\n",
    "- Keywords AI base URL (`KEYWORDSAI_BASE_URL`) \n",
    "- Python packages: `keywordsai`, `python-dotenv` (installed via Poetry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded successfully\n",
      "üîë API Key: ptIwf5dO.g...FGoP\n",
      "üåê Base URL: http://localhost:8000/api\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import asyncio\n",
    "from datetime import datetime, timezone\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Keywords AI imports\n",
    "from keywordsai.experiments.api import ExperimentAPI\n",
    "from keywordsai_sdk.keywordsai_types.experiment_types import ExperimentType\n",
    "from keywordsai import (\n",
    "    ExperimentList,\n",
    "    ExperimentCreate,\n",
    "    ExperimentColumnType,\n",
    "    ExperimentRowType,\n",
    "    AddExperimentRowsRequest,\n",
    "    AddExperimentColumnsRequest,\n",
    "    RunExperimentRequest,\n",
    "    RunExperimentEvalsRequest,\n",
    "    ExperimentUpdate\n",
    ")\n",
    "\n",
    "# Check environment variables\n",
    "api_key = os.getenv(\"KEYWORDSAI_API_KEY\")\n",
    "base_url = os.getenv(\"KEYWORDSAI_BASE_URL\")\n",
    "\n",
    "if not api_key or not base_url:\n",
    "    print(\"‚ùå Missing environment variables!\")\n",
    "    print(\"Please set KEYWORDSAI_API_KEY and KEYWORDSAI_BASE_URL in your .env file\")\n",
    "else:\n",
    "    print(\"‚úÖ Environment variables loaded successfully\")\n",
    "    print(f\"üîë API Key: {api_key[:10]}...{api_key[-4:] if len(api_key) > 14 else api_key}\")\n",
    "    print(f\"üåê Base URL: {base_url}\")\n",
    "\n",
    "# Initialize the Experiment API client\n",
    "client = ExperimentAPI(api_key=api_key, base_url=base_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Phase 1: Basic Experiment Creation\n",
    "\n",
    "### Step 1: Create Initial Experiment\n",
    "\n",
    "Let's start by creating a new experiment with one model configuration and one test case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Creating a new Experiment...\n",
      "‚úÖ Created experiment with ID: 48b6c352e80548d69137113ac3354569\n"
     ]
    }
   ],
   "source": [
    "print(\"üìù Creating a new Experiment...\")\n",
    "\n",
    "# Create basic prompt\n",
    "experiment_data = ExperimentType(\n",
    "    name=\"Customer Support Assistant\",\n",
    "    description=\"AI assistant for handling customer support inquiries with professional tone\",\n",
    ")\n",
    "experiment = await client.acreate(experiment_data)\n",
    "experiment_id = experiment.id\n",
    "print(f\"‚úÖ Created experiment with ID: {experiment.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Step 2: Create column\n",
    "\n",
    "Create column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Step 2: Creating a column...\n",
      "[Message(role='system', content=[TextContent(type='text', text='You are a friendly customer support assistant. Use a warm, professional tone while solving customer problems efficiently.', cache_control=None)], name=None, tool_call_id=None, tool_calls=None, reasoning_content=None, thinking_blocks=None), Message(role='user', content=[TextContent(type='text', text='{{customer_inquiry}}', cache_control=None)], name=None, tool_call_id=None, tool_calls=None, reasoning_content=None, thinking_blocks=None)]\n",
      "‚úÖ Added Expert Assistant column (column1), and Expert Assistant column with prompt_messages from current version (column2)\n",
      "üìä Experiment now has 12 total columns\n",
      "\n",
      "üîß Column Configuration:\n",
      "   Name: Expert Assistant\n",
      "   Model: gpt-4\n",
      "   Temperature: 0.3\n",
      "   Max tokens: 250\n",
      "   System prompt: You are a friendly customer support assistant. Use a warm, professional tone while solving customer problems efficiently.\n",
      "\n",
      "üí° Column created successfully! Ready to add test cases.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create a column (model configuration)\n",
    "print(\"ü§ñ Step 2: Creating a column...\")\n",
    "\n",
    "\n",
    "# Create a column with specific parameters\n",
    "column1 = ExperimentColumnType(\n",
    "    model=\"gpt-4\",\n",
    "    name=\"Expert Assistant\",\n",
    "    temperature=0.3,\n",
    "    max_completion_tokens=250,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    prompt_messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert technical assistant. Provide accurate, detailed explanations with examples when helpful.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"{{question}}\"\n",
    "        }\n",
    "    ],\n",
    "    tools=[],\n",
    "    tool_choice=\"auto\",\n",
    "    response_format={\"type\": \"text\"}\n",
    ")\n",
    "from keywordsai.prompts.api import PromptAPI\n",
    "prompt_id = \"98db4236865d4abbb1ca5d88ce4ac3e3\"\n",
    "prompt_client = PromptAPI(api_key=api_key, base_url=base_url)\n",
    "prompt = await prompt_client.aget(prompt_id)\n",
    "print(prompt.current_version.messages)\n",
    "def to_messages(msgs):\n",
    "    out = []\n",
    "    for m in msgs:\n",
    "        # m.content may be a list of TextContent(...) or a plain string\n",
    "        if isinstance(m.content, list):\n",
    "            text = \"\".join(getattr(c, \"text\", \"\") for c in m.content if getattr(c, \"type\", None) == \"text\")\n",
    "        else:\n",
    "            text = m.content\n",
    "        out.append({\"role\": m.role, \"content\": text})\n",
    "    return out\n",
    "\n",
    "column2 = ExperimentColumnType(\n",
    "    model=\"gpt-4\",\n",
    "    name=\"Expert Assistant\",\n",
    "    temperature=0.3,\n",
    "    max_completion_tokens=250,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    prompt_messages=to_messages(prompt.current_version.messages),\n",
    "    tools=[],\n",
    "    tool_choice=\"auto\",\n",
    "    response_format={\"type\": \"text\"}\n",
    ")\n",
    "\n",
    "add_columns_request = AddExperimentColumnsRequest(columns=[column1, column2])\n",
    "await client.aadd_columns(experiment_id, add_columns_request)\n",
    "print(\"‚úÖ Added Expert Assistant column (column1), and Expert Assistant column with prompt_messages from current version (column2)\")\n",
    "\n",
    "# Verify the column was added\n",
    "updated_experiment = await client.aget(experiment_id)\n",
    "print(f\"üìä Experiment now has {len(updated_experiment.columns)} total columns\")\n",
    "\n",
    "# Show the column configuration\n",
    "print(f\"\\nüîß Column configuration for the latest column:\")\n",
    "latest_column = updated_experiment.columns[-1]  # Get the last added column\n",
    "print(f\"   Name: {latest_column.name}\")\n",
    "print(f\"   Model: {latest_column.model}\")\n",
    "print(f\"   Temperature: {latest_column.temperature}\")\n",
    "print(f\"   Max tokens: {latest_column.max_completion_tokens}\")\n",
    "print(f\"   System prompt: {latest_column.prompt_messages[0]['content']}\")\n",
    "\n",
    "print(f\"\\nüí° Columsn created successfully! Ready to add test cases.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Phase 2: Expanding the Experiment\n",
    "\n",
    "### Step 3: Add Test Cases (Rows)\n",
    "\n",
    "Let's add more test cases to evaluate our model configurations across different scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Step 3: Adding more test cases...\n",
      "‚úÖ Added 4 new test cases\n",
      "üìä Experiment now has 4 total rows\n",
      "\n",
      "üìù All Test Cases:\n",
      "   1. What is machine learning?\n",
      "      Expected: ML is a subset of AI that learns from data.\n",
      "   2. Explain neural networks briefly.\n",
      "      Expected: Neural networks are computing systems inspired by biological neural networks.\n",
      "   3. What is the difference between AI and ML?\n",
      "      Expected: (No ideal output provided)\n",
      "   4. How does deep learning work?\n",
      "      Expected: Deep learning uses multi-layered neural networks to learn complex patterns.\n"
     ]
    }
   ],
   "source": [
    "# Add more test cases (rows)\n",
    "print(\"üìù Step 3: Adding more test cases...\")\n",
    "\n",
    "new_rows = [\n",
    "    ExperimentRowType(\n",
    "        input={\"question\": \"What is machine learning?\"},\n",
    "        ideal_output=\"ML is a subset of AI that learns from data.\"\n",
    "    ),\n",
    "    ExperimentRowType(\n",
    "        input={\"question\": \"Explain neural networks briefly.\"},\n",
    "        ideal_output=\"Neural networks are computing systems inspired by biological neural networks.\"\n",
    "    ),\n",
    "    ExperimentRowType(\n",
    "        input={\"question\": \"What is the difference between AI and ML?\"}\n",
    "        # No ideal_output for this one - let's see how models handle it\n",
    "    ),\n",
    "    ExperimentRowType(\n",
    "        input={\"question\": \"How does deep learning work?\"},\n",
    "        ideal_output=\"Deep learning uses multi-layered neural networks to learn complex patterns.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "add_rows_request = AddExperimentRowsRequest(rows=new_rows)\n",
    "\n",
    "await client.aadd_rows(experiment_id, add_rows_request)\n",
    "print(f\"‚úÖ Added {len(new_rows)} new test cases\")\n",
    "\n",
    "# Verify the rows were added\n",
    "updated_experiment = await client.aget(experiment_id)\n",
    "print(f\"üìä Experiment now has {len(updated_experiment.rows)} total rows\")\n",
    "\n",
    "# Show all test cases\n",
    "print(f\"\\nüìù All Test Cases:\")\n",
    "for i, row in enumerate(updated_experiment.rows, 1):\n",
    "    question = row.input.get('question', 'Unknown')\n",
    "    print(f\"   {i}. {question}\")\n",
    "    if hasattr(row, 'ideal_output') and row.ideal_output:\n",
    "        print(f\"      Expected: {row.ideal_output}\")\n",
    "    else:\n",
    "        print(f\"      Expected: (No ideal output provided)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Step 4: Add Model Configurations (Columns)\n",
    "\n",
    "Now let's add a second model configuration to compare different approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Step 4: Adding another model configuration...\n",
      "‚úÖ Added GPT-4 Expert Assistant configuration\n",
      "üìä Experiment now has 3 total columns\n",
      "\n",
      "üîß Model Configurations:\n",
      "   Column 1: Expert Assistant\n",
      "   - Model: gpt-4\n",
      "   - Temperature: 0.3\n",
      "   - Max tokens: 250\n",
      "   - System prompt: You are an expert technical assistant. Provide acc...\n",
      "\n",
      "   Column 2: Expert Assistant\n",
      "   - Model: gpt-4\n",
      "   - Temperature: 0.3\n",
      "   - Max tokens: 250\n",
      "   - System prompt: You are an expert technical assistant. Provide acc...\n",
      "\n",
      "   Column 3: Expert Assistant\n",
      "   - Model: gpt-4o\n",
      "   - Temperature: 0.2\n",
      "   - Max tokens: 270\n",
      "   - System prompt: You are an expert technical assistant. Provide acc...\n",
      "\n",
      "üí° Now we can compare how GPT-3.5 vs GPT-4 handle the same questions!\n"
     ]
    }
   ],
   "source": [
    "# Add another model configuration (column)\n",
    "print(\"ü§ñ Step 4: Adding another model configuration...\")\n",
    "\n",
    "# Create a second column with different parameters\n",
    "expert_column = ExperimentColumnType(\n",
    "    model=\"gpt-4o\",\n",
    "    name=\"Expert Assistant\",\n",
    "    temperature=0.2,  # Lower temperature for more focused responses\n",
    "    max_completion_tokens=270,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    prompt_messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert technical assistant. Provide accurate, detailed explanations with examples when helpful.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"{{question}}\"\n",
    "        }\n",
    "    ],\n",
    "    tools=[],\n",
    "    tool_choice=\"auto\",\n",
    "    response_format={\"type\": \"text\"}\n",
    ")\n",
    "\n",
    "add_columns_request = AddExperimentColumnsRequest(columns=[expert_column])\n",
    "await client.aadd_columns(experiment_id, add_columns_request)\n",
    "print(\"‚úÖ Added GPT-4 Expert Assistant configuration\")\n",
    "\n",
    "# Verify the column was added\n",
    "updated_experiment = await client.aget(experiment_id)\n",
    "print(f\"üìä Experiment now has {len(updated_experiment.columns)} total columns\")\n",
    "\n",
    "# Show all configurations\n",
    "print(f\"\\nüîß Model Configurations:\")\n",
    "for i, col in enumerate(updated_experiment.columns, 1):\n",
    "    print(f\"   Column {i}: {col.name}\")\n",
    "    print(f\"   - Model: {col.model}\")\n",
    "    print(f\"   - Temperature: {col.temperature}\")\n",
    "    print(f\"   - Max tokens: {col.max_completion_tokens}\")\n",
    "    print(f\"   - System prompt: {col.prompt_messages[0]['content'][:50]}...\")\n",
    "    print()\n",
    "\n",
    "print(f\"üí° Now we can compare how GPT-3.5 vs GPT-4 handle the same questions!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Step 5: Update Experiment Metadata\n",
    "\n",
    "Let's update the experiment name and description to reflect our changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úèÔ∏è Step 5: Updating experiment metadata...\n",
      "‚úÖ Updated experiment name to: updated\n",
      "üìã New description: \n",
      "\n",
      "üìä Final Experiment Structure:\n",
      "   - Name: updated\n",
      "   - Columns: 3 (model configurations)\n",
      "   - Rows: 4 (test cases)\n",
      "   - Status: \n",
      "   - Total combinations: 3 √ó 4 = 12\n",
      "\n",
      "üöÄ The experiment is now ready to run!\n"
     ]
    }
   ],
   "source": [
    "# Update experiment metadata\n",
    "print(\"‚úèÔ∏è Step 5: Updating experiment metadata...\")\n",
    "\n",
    "update_data = ExperimentUpdate(\n",
    "    name=f\"updated\",\n",
    "    description=\"Comprehensive AI comparison experiment with GPT-3.5 vs GPT-4 across multiple technical questions\"\n",
    ")\n",
    "\n",
    "updated_experiment = await client.aupdate(experiment_id, update_data)\n",
    "print(f\"‚úÖ Updated experiment name to: {updated_experiment.name}\")\n",
    "print(f\"üìã New description: {updated_experiment.description}\")\n",
    "\n",
    "# Show final experiment structure\n",
    "print(f\"\\nüìä Final Experiment Structure:\")\n",
    "print(f\"   - Name: {updated_experiment.name}\")\n",
    "print(f\"   - Columns: {len(updated_experiment.columns)} (model configurations)\")\n",
    "print(f\"   - Rows: {len(updated_experiment.rows)} (test cases)\")\n",
    "print(f\"   - Status: {updated_experiment.status}\")\n",
    "print(f\"   - Total combinations: {len(updated_experiment.columns)} √ó {len(updated_experiment.rows)} = {len(updated_experiment.columns) * len(updated_experiment.rows)}\")\n",
    "\n",
    "print(f\"\\nüöÄ The experiment is now ready to run!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Step 6: List All Experiments\n",
    "\n",
    "Let's see how to manage multiple experiments and find the one we created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results=[ExperimentType(id='4', column_count=1, columns=[], created_at='2025-07-21T19:34:21.997000Z', created_by=1, name='asdfadsf', organization=1, row_count=1, rows=[], status='ready', test_id='001Kun', updated_at='2025-07-21T19:34:22.034885Z', updated_by=1, variables=[], variable_definitions=[], starred=True, tags=[], description=''), ExperimentType(id='1a9f1edcc1b84f6390370313d41516b2', column_count=0, columns=[], created_at='2025-08-22T06:21:30.556743Z', created_by=1, name='Customer Support Assistant', organization=1, row_count=0, rows=[], status='', test_id='1a9f1edcc1b84f6390370313d41516b2', updated_at='2025-08-22T06:21:30.556775Z', updated_by=1, variables=[], variable_definitions=[], starred=False, tags=[], description=''), ExperimentType(id='91fdba26697f4ea1abd095a64e153afb', column_count=0, columns=[], created_at='2025-08-22T06:21:14.536972Z', created_by=1, name='Customer Support Assistant', organization=1, row_count=0, rows=[], status='', test_id='91fdba26697f4ea1abd095a64e153afb', updated_at='2025-08-22T06:21:14.536999Z', updated_by=1, variables=[], variable_definitions=[], starred=False, tags=[], description=''), ExperimentType(id='29d00c1a7a0b4a7b8ebcc44737a480fb', column_count=0, columns=[], created_at='2025-08-22T06:21:13.734428Z', created_by=1, name='Customer Support Assistant', organization=1, row_count=0, rows=[], status='', test_id='29d00c1a7a0b4a7b8ebcc44737a480fb', updated_at='2025-08-22T06:21:13.734483Z', updated_by=1, variables=[], variable_definitions=[], starred=False, tags=[], description=''), ExperimentType(id='60754a6daed34caca93d3fae8e4fced9', column_count=0, columns=[], created_at='2025-08-22T06:21:29.735194Z', created_by=1, name='Customer Support Assistant', organization=1, row_count=0, rows=[], status='', test_id='60754a6daed34caca93d3fae8e4fced9', updated_at='2025-08-22T06:21:29.735222Z', updated_by=1, variables=[], variable_definitions=[], starred=False, tags=[], description='')] count=5 next='http://localhost:8000/api/experiments/list?page=2&page_size=5' previous=None\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "listed_experiments = await client.alist(page_size=5)\n",
    "print(listed_experiments)\n",
    "print(len(listed_experiments.results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Run experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running experiment...\n",
      "loading...\n",
      "‚úÖ Run results: {'id': '48b6c352e80548d69137113ac3354569', 'updater': {'first_name': 'Leon', 'last_name': 'Lian', 'email': 'leonxlian@gmail.com'}, 'column_count': 2, 'columns': [{'id': 'a992e03837c94527aa2a010d429ac2bd', 'name': 'Expert Assistant', 'model': 'gpt-4', 'tools': [], 'top_p': 1.0, 'stream': False, 'temperature': 0.3, 'tool_choice': 'auto', 'prompt_messages': [{'role': 'system', 'content': 'You are an expert technical assistant. Provide accurate, detailed explanations with examples when helpful.'}, {'role': 'user', 'content': '{{question}}'}], 'response_format': {'type': 'text'}, 'presence_penalty': 0.0, 'frequency_penalty': 0.0, 'max_completion_tokens': 250}, {'id': '3f0122282b8247af96577184e7bb3131', 'name': 'Expert Assistant', 'model': 'gpt-4', 'tools': [], 'top_p': 1.0, 'stream': False, 'temperature': 0.3, 'tool_choice': 'auto', 'prompt_messages': [{'role': 'system', 'content': 'You are an expert technical assistant. Provide accurate, detailed explanations with examples when helpful.'}, {'role': 'user', 'content': '{{question}}'}], 'response_format': {'type': 'text'}, 'presence_penalty': 0.0, 'frequency_penalty': 0.0, 'max_completion_tokens': 250}], 'created_at': '2025-08-26T20:44:39.196889Z', 'name': 'updated', 'row_count': 2, 'rows': [{'id': '609d74961115434eb96a6d9d814cd629', 'input': {'question': 'What is the difference between AI and ML?'}, 'status': 'ready', 'results': [{'id': '33d003d128194ec4924c706ee700289c', 'column_id': 'a992e03837c94527aa2a010d429ac2bd', 'output': {'content': \"Artificial Intelligence (AI) and Machine Learning (ML) are two very important terms in the field of computer science. However, they are often used interchangeably, which is incorrect. Here's a detailed explanation of the differences between AI and ML:\\n\\n1. **Definition:**\\n   - **AI (Artificial Intelligence):** AI is a broader concept that refers to machines or computers that mimic human intelligence in performing tasks, which normally require human intelligence to complete. This includes tasks like learning, reasoning, problem-solving, perception, and language understanding.\\n   - **ML (Machine Learning):** ML is a subset of AI. It refers to the concept that a machine can learn and adapt its performance without being explicitly programmed to do so. It focuses on the development of algorithms that can teach themselves to grow and change when exposed to new data.\\n\\n2. **Goal:**\\n   - **AI:** The primary goal of AI is to make a smart computer system like humans to solve complex problems.\\n   - **ML:** The primary goal of ML is to allow machines to learn from data so they can give accurate output.\\n\\n3. **Learning:**\\n   - **AI:** In AI, the system needs to be programmed for each and every task\", 'role': 'assistant', 'annotations': []}, 'error': None, 'ran_at': '2025-08-26T20:50:32.224253+00:00', 'status': 'completed', 'evaluation_result': None, 'llm_inference_metrics': None}, {'id': 'ff30cc943cdb4f81aa5fadaf2ff1e499', 'column_id': '3f0122282b8247af96577184e7bb3131', 'output': {'content': 'Artificial Intelligence (AI) and Machine Learning (ML) are two very important terms in the world of computer science. While they are often used interchangeably, they do not mean the same thing. \\n\\nAI is a broader concept that refers to machines or computers that mimic cognitive functions that humans associate with the human mind, such as learning and problem-solving. AI can be categorized as either weak AI, where the machine is made to perform a specific task (e.g., voice recognition), or strong AI, where the machine can perform any intellectual task that a human being can.\\n\\nOn the other hand, ML is a subset of AI that involves the practice of using algorithms to parse data, learn from it, and then make a determination or prediction about something. Instead of hand-coding software routines with a specific set of instructions to accomplish a particular task, the machine is trained using large amounts of data and algorithms to learn how to perform the task.\\n\\nFor example, a machine learning model could be trained on email messages to learn to distinguish between spam and non-spam messages. After learning, it can then classify new email messages into spam and non-spam folders.\\n\\nIn summary, AI is a broader concept, while ML is a specific subset of AI', 'role': 'assistant', 'annotations': []}, 'error': None, 'ran_at': '2025-08-26T20:50:41.115549+00:00', 'status': 'completed', 'evaluation_result': None, 'llm_inference_metrics': None}], 'ideal_output': None}, {'id': '24d3d06052e142c28b0868538d3d979b', 'input': {'question': 'How does deep learning work?'}, 'status': 'ready', 'results': [{'id': 'b00f161f16074e66a261995d63e11a9a', 'column_id': 'a992e03837c94527aa2a010d429ac2bd', 'output': {'content': \"Deep Learning is a subset of Machine Learning, which in turn is a subset of Artificial Intelligence (AI). It involves the use of artificial neural networks with several layers - these are the 'deep' structures that have led to the name 'Deep Learning'. These deep structures allow the machine to process data in a very sophisticated way, learning through its own method of trial and error.\\n\\nHere's a more detailed explanation:\\n\\n1. **Data Collection**: The first step in deep learning is to collect a large amount of data related to the problem you are trying to solve. For example, if you're trying to create a system that can recognize images of dogs, you would start by collecting thousands (or even millions) of images of dogs.\\n\\n2. **Preprocessing**: Once the data is collected, it needs to be preprocessed. This could involve resizing images, converting text to numerical data, or performing other transformations to make the data easier for the system to understand.\\n\\n3. **Building the Model**: Next, a model is built. This model is a neural network that consists of multiple layers. Each layer takes input from the previous layer, performs some calculations on it, and passes its output to the next layer. The first layer of the network is\", 'role': 'assistant', 'annotations': []}, 'error': None, 'ran_at': '2025-08-26T20:50:48.700493+00:00', 'status': 'completed', 'evaluation_result': None, 'llm_inference_metrics': None}, {'id': 'e049a78071634e26bbe563a99c4739cd', 'column_id': '3f0122282b8247af96577184e7bb3131', 'output': {'content': \"Deep Learning is a subset of Machine Learning, which in turn is a branch of Artificial Intelligence (AI). It works by imitating the workings of the human brain in processing data for use in decision making.\\n\\nDeep Learning involves the use of artificial neural networks with several layers (hence the term 'deep'). These neural networks attempt to simulate the behavior of the human brain‚Äîalbeit far from matching its ability‚Äîin order to 'learn' from large amounts of data. While a neural network with a single layer can still make approximate predictions, additional hidden layers can help optimize the accuracy.\\n\\nHere's a simplified explanation of how deep learning works:\\n\\n1. **Data Collection**: The first step in the deep learning process is to collect large amounts of data related to the problem you're trying to solve. For example, if you're trying to create a deep learning model that can recognize images of cats, you would start by collecting thousands (or even millions) of cat images.\\n\\n2. **Preprocessing**: The collected data is then preprocessed to convert it into a format that can be understood by the neural network. For example, images might be resized and their pixel values normalized.\\n\\n3. **Building the Model**: A neural network model is then created with\", 'role': 'assistant', 'annotations': []}, 'error': None, 'ran_at': '2025-08-26T20:50:56.996569+00:00', 'status': 'completed', 'evaluation_result': None, 'llm_inference_metrics': None}], 'ideal_output': 'Deep learning uses multi-layered neural networks to learn complex patterns.'}], 'status': '', 'test_id': '48b6c352e80548d69137113ac3354569', 'updated_at': '2025-08-26T20:44:39.196944Z', 'variables': [], 'variable_definitions': [], 'starred': False, 'created_by': 1, 'organization': 1, 'updated_by': 1, 'tags': []}\n"
     ]
    }
   ],
   "source": [
    "# Run experiment with extended timeout (avoids ReadTimeout)\n",
    "print(\"üöÄ Running experiment...\")\n",
    "print(\"loading...\")\n",
    "result = await client.arun_experiment(experiment_id)\n",
    "print(\"‚úÖ Run results:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Phase 3: Managing Experiment Content\n",
    "\n",
    "### Step 8: Delete Rows and Columns\n",
    "\n",
    "Now let's learn how to remove test cases (rows) and model configurations (columns) from experiments. This is useful for cleaning up experiments or removing configurations that aren't working well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Step 7: Delete first 2 rows...\n",
      "üìä Current rows: 4\n",
      "   1. What is machine learning?\n",
      "   2. Explain neural networks briefly.\n",
      "   3. What is the difference between AI and ML?\n",
      "   4. How does deep learning work?\n",
      "üóëÔ∏è Will delete: What is machine learning?\n",
      "üóëÔ∏è Will delete: Explain neural networks briefly.\n",
      "‚úÖ Done! Deleted 2 rows. Now have 2 rows\n"
     ]
    }
   ],
   "source": [
    "# Delete first 2 rows\n",
    "print(\"üóëÔ∏è Step 7: Delete first 2 rows...\")\n",
    "\n",
    "from keywordsai import RemoveExperimentRowsRequest\n",
    "\n",
    "# Get current experiment\n",
    "experiment = await client.aget(experiment_id)\n",
    "print(f\"üìä Current rows: {len(experiment.rows)}\")\n",
    "\n",
    "# Show current rows\n",
    "for i, row in enumerate(experiment.rows):\n",
    "    question = row.input.get('question', 'Unknown')\n",
    "    print(f\"   {i+1}. {question}\")\n",
    "\n",
    "# Get first 2 row IDs\n",
    "rows_to_delete = []\n",
    "for row in experiment.rows[:2]:  # Take first 2 rows\n",
    "    row_id = getattr(row, 'id', None)\n",
    "    if row_id:\n",
    "        rows_to_delete.append(row_id)\n",
    "        print(f\"üóëÔ∏è Will delete: {row.input.get('question', 'Unknown')}\")\n",
    "\n",
    "# Delete them\n",
    "remove_request = RemoveExperimentRowsRequest(rows=rows_to_delete)\n",
    "await client.aremove_rows(experiment_id, remove_request)\n",
    "\n",
    "# Check result\n",
    "updated = await client.aget(experiment_id)\n",
    "print(f\"‚úÖ Done! Deleted {len(rows_to_delete)} rows. Now have {len(updated.rows)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Delete one column...\n",
      "üìä Current columns: 3\n",
      "   1. Expert Assistant (gpt-4)\n",
      "   2. Expert Assistant (gpt-4)\n",
      "   3. Expert Assistant (gpt-4o)\n",
      "\n",
      "üóëÔ∏è Deleting: Expert Assistant\n",
      "‚úÖ Done! Now have 2 columns\n"
     ]
    }
   ],
   "source": [
    "# Simple delete one column\n",
    "print(\"üóëÔ∏è Delete one column...\")\n",
    "\n",
    "from keywordsai import RemoveExperimentColumnsRequest\n",
    "\n",
    "# Get current experiment\n",
    "experiment = await client.aget(experiment_id)\n",
    "print(f\"üìä Current columns: {len(experiment.columns)}\")\n",
    "\n",
    "# Show current columns\n",
    "for i, col in enumerate(experiment.columns):\n",
    "    print(f\"   {i+1}. {col.name} ({col.model})\")\n",
    "\n",
    "last_column = experiment.columns[-1]\n",
    "column_id = getattr(last_column, 'id', None)\n",
    "\n",
    "if column_id:\n",
    "    print(f\"\\nüóëÔ∏è Deleting: {last_column.name}\")\n",
    "    \n",
    "    # Delete it\n",
    "    remove_request = RemoveExperimentColumnsRequest(columns=[column_id])\n",
    "    await client.aremove_columns(experiment_id, remove_request)\n",
    "    \n",
    "    # Check result\n",
    "    updated = await client.aget(experiment_id)\n",
    "    print(f\"‚úÖ Done! Now have {len(updated.columns)} columns\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Could not find column ID\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
