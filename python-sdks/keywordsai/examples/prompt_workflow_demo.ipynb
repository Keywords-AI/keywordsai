{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Keywords AI Prompt Management Workflow Demo\n",
        "\n",
        "This notebook demonstrates the complete workflow for managing prompts in Keywords AI, including creation, versioning, deployment, and usage with OpenAI SDK.\n",
        "\n",
        "## What are Prompts in Keywords AI?\n",
        "\n",
        "Keywords AI prompts are reusable templates that define AI model configurations, system messages, and parameters. They enable version control, A/B testing, and centralized prompt management. Each prompt can have multiple versions with different settings, allowing you to iterate and deploy the best-performing configurations. Prompts integrate seamlessly with OpenAI SDK through Keywords AI's gateway, providing analytics and monitoring for all your AI interactions.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Keywords AI API key (`KEYWORDSAI_API_KEY`)\n",
        "- Keywords AI base URL (`KEYWORDSAI_BASE_URL`) \n",
        "- Python packages: `keywordsai`, `openai`, `python-dotenv`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import os\n",
        "import asyncio\n",
        "from datetime import datetime, timezone\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(override=True)\n",
        "\n",
        "# Keywords AI imports\n",
        "from keywordsai.prompts.api import PromptAPI\n",
        "from keywordsai_sdk.keywordsai_types.prompt_types import Prompt, PromptVersion\n",
        "\n",
        "# Check environment variables\n",
        "api_key = os.getenv(\"KEYWORDSAI_API_KEY\")\n",
        "base_url = os.getenv(\"KEYWORDSAI_BASE_URL\")\n",
        "\n",
        "if not api_key or not base_url:\n",
        "    print(\"‚ùå Missing environment variables!\")\n",
        "    print(\"Please set KEYWORDSAI_API_KEY and KEYWORDSAI_BASE_URL in your .env file\")\n",
        "else:\n",
        "    print(\"‚úÖ Environment variables loaded successfully\")\n",
        "    print(f\"üîë API Key: {api_key[:10]}...{api_key[-4:] if len(api_key) > 14 else api_key}\")\n",
        "    print(f\"üåê Base URL: {base_url}\")\n",
        "\n",
        "# Initialize the Prompt API client\n",
        "client = PromptAPI(api_key=api_key, base_url=base_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create a New Prompt\n",
        "\n",
        "Let's start by creating a new prompt that will serve as our container for different versions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new prompt\n",
        "print(\"üìù Creating a new prompt...\")\n",
        "\n",
        "# Create basic prompt\n",
        "prompt = await client.acreate()\n",
        "print(f\"‚úÖ Created prompt with ID: {prompt.prompt_id}\")\n",
        "print(f\"   Name: {prompt.name}\")\n",
        "print(f\"   Description: {prompt.description}\")\n",
        "\n",
        "# Update the prompt with meaningful information\n",
        "print(\"\\n‚úèÔ∏è  Updating prompt metadata...\")\n",
        "updated_prompt_data = Prompt(\n",
        "    name=\"Customer Support Assistant\",\n",
        "    description=\"AI assistant for handling customer support inquiries with professional tone\",\n",
        "    prompt_id=prompt.prompt_id,  # Include the required prompt_id\n",
        ")\n",
        "\n",
        "updated_prompt = await client.aupdate(prompt.prompt_id, updated_prompt_data)\n",
        "print(f\"‚úÖ Updated prompt: {updated_prompt.name}\")\n",
        "print(f\"üìã Description: {updated_prompt.description}\")\n",
        "\n",
        "# Store the prompt ID for later use\n",
        "PROMPT_ID = updated_prompt.prompt_id\n",
        "print(f\"\\nüîó Prompt ID for reference: {PROMPT_ID}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üåê Browse the Keywords AI UI\n",
        "\n",
        "**Now is a good time to visit the Keywords AI platform UI!**\n",
        "\n",
        "1. Go to your Keywords AI dashboard: `https://platform.keywordsai.co`\n",
        "2. Navigate to the **Prompts** section\n",
        "3. Find the prompt you just created: \"Customer Support Assistant\"\n",
        "4. Notice that it currently has no versions - you'll need to create one!\n",
        "\n",
        "The UI provides a visual interface for managing prompts, but we'll continue with the API to show the complete programmatic workflow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create a Prompt Version\n",
        "\n",
        "Now let's create a version of our prompt with specific configuration, messages, and model parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a prompt version with specific configuration\n",
        "print(\"üîß Creating a prompt version...\")\n",
        "\n",
        "version_data = PromptVersion(\n",
        "    prompt_version_id=\"version-001\",\n",
        "    description=\"Initial customer support version with professional tone\",\n",
        "    created_at=datetime.now(timezone.utc),\n",
        "    updated_at=datetime.now(timezone.utc),\n",
        "    version=1,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional customer support assistant. Always be helpful, polite, and provide clear solutions to customer problems.\",\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": \"{{customer_inquiry}}\"},\n",
        "    ],\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=2048,\n",
        "    top_p=1.0,\n",
        "    frequency_penalty=0.0,\n",
        "    presence_penalty=0.0,\n",
        "    variables={\"customer_inquiry\": \"Customer's question or issue\"},\n",
        "    parent_prompt=PROMPT_ID,\n",
        ")\n",
        "\n",
        "version = await client.acreate_version(PROMPT_ID, version_data)\n",
        "print(f\"‚úÖ Created version {version.version}\")\n",
        "print(f\"   Model: {version.model}\")\n",
        "print(f\"   Temperature: {version.temperature}\")\n",
        "print(f\"   Messages: {len(version.messages)} messages\")\n",
        "print(f\"   Variables: {version.variables}\")\n",
        "\n",
        "# Store version info for later use\n",
        "VERSION_1 = version.version\n",
        "print(f\"\\nüîó Version {VERSION_1} created successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Update a Prompt Version\n",
        "\n",
        "Let's update our version to demonstrate how you can modify existing versions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, let's check if the version is readonly\n",
        "retrieved_version = await client.aget_version(PROMPT_ID, VERSION_1)\n",
        "print(f\"üîç Version {retrieved_version.version} details:\")\n",
        "print(f\"   Description: {retrieved_version.description}\")\n",
        "print(f\"   Readonly: {retrieved_version.readonly}\")\n",
        "\n",
        "if retrieved_version.readonly:\n",
        "    print(f\"\\n‚ö†Ô∏è  Version {retrieved_version.version} is readonly - cannot update\")\n",
        "    print(\"   This is expected behavior - versions may become readonly after creation\")\n",
        "else:\n",
        "    print(f\"\\n‚úèÔ∏è  Updating version {VERSION_1}...\")\n",
        "    # Only send the fields we want to update, not a full PromptVersion object\n",
        "    update_version_data = {\n",
        "        \"description\": \"Updated: Professional customer support with improved clarity\",\n",
        "        \"temperature\": 0.6,  # Slightly lower temperature\n",
        "        \"max_tokens\": 2500,  # More tokens\n",
        "    }\n",
        "    \n",
        "    updated_version = await client.aupdate_version(\n",
        "        PROMPT_ID, VERSION_1, update_version_data\n",
        "    )\n",
        "    print(f\"‚úÖ Updated version {updated_version.version}\")\n",
        "    print(f\"   New description: {updated_version.description}\")\n",
        "    print(f\"   New temperature: {updated_version.temperature}\")\n",
        "    print(f\"   New max_tokens: {updated_version.max_tokens}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Setup OpenAI Client with Keywords AI\n",
        "\n",
        "Now let's setup the OpenAI client to use Keywords AI as the gateway. This allows us to use our prompts with the standard OpenAI SDK.\n",
        "\n",
        "Reference: [Keywords AI OpenAI SDK Integration](https://docs.keywordsai.co/integration/development-frameworks/llm_framework/openai/openai-sdk)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup OpenAI client to use Keywords AI gateway\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client with Keywords AI endpoint\n",
        "openai_client = OpenAI(\n",
        "    base_url=f\"{base_url.rstrip('/')}/api/\",  # Keywords AI gateway endpoint\n",
        "    api_key=api_key,  # Use your Keywords AI API key\n",
        ")\n",
        "\n",
        "print(\"‚úÖ OpenAI client configured to use Keywords AI gateway\")\n",
        "print(f\"üîó Gateway URL: {base_url.rstrip('/')}/api/\")\n",
        "print(\"\\nüí° This allows you to:\")\n",
        "print(\"   - Use Keywords AI prompts with OpenAI SDK\")\n",
        "print(\"   - Access 250+ models through one interface\")\n",
        "print(\"   - Get detailed analytics and monitoring\")\n",
        "print(\"   - Manage fallbacks and error handling\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Define a reusable function for prompt-based chat completions\n",
        "def chat_with_prompt(\n",
        "    client, \n",
        "    prompt_id, \n",
        "    variables=None, \n",
        "    model=\"gpt-4o-mini\",\n",
        "    customer_identifier=None,\n",
        "    metadata=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Make a chat completion using a Keywords AI prompt.\n",
        "    Shows the exact extra_body structure being sent for educational purposes.\n",
        "    \n",
        "    Args:\n",
        "        client: OpenAI client configured for Keywords AI\n",
        "        prompt_id: ID of the prompt to use\n",
        "        variables: Dict of variables to substitute in the prompt\n",
        "        model: Model to use (default: gpt-4o-mini)\n",
        "        customer_identifier: Optional customer identifier for tracking\n",
        "        metadata: Optional metadata dict for analytics\n",
        "    \n",
        "    Returns:\n",
        "        OpenAI ChatCompletion response\n",
        "    \"\"\"\n",
        "    # Build the correct extra_body structure\n",
        "    extra_body = {\n",
        "        \"prompt\": {\n",
        "            \"prompt_id\": prompt_id,\n",
        "        },\n",
        "    }\n",
        "    \n",
        "    if variables:\n",
        "        extra_body[\"prompt\"][\"variables\"] = variables\n",
        "    \n",
        "    if customer_identifier:\n",
        "        extra_body[\"customer_identifier\"] = customer_identifier\n",
        "        \n",
        "    if metadata:\n",
        "        extra_body[\"metadata\"] = metadata\n",
        "    \n",
        "    # Print the structure so users can see exactly what's being sent\n",
        "    print(f\"üîß Keywords AI Extra Body Structure:\")\n",
        "    print(json.dumps(extra_body, indent=2))\n",
        "    print()\n",
        "    \n",
        "    return client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \".\",  # Placeholder for OAI SDK, will be replaced by the prompt\n",
        "            }\n",
        "        ],\n",
        "        extra_body=extra_body,\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Reusable chat_with_prompt function defined\")\n",
        "print(\"   ‚Ä¢ This function shows the correct extra_body structure\")\n",
        "print(\"   ‚Ä¢ Use this instead of manually building extra_body\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Try to Use the Prompt (Expected Error)\n",
        "\n",
        "Let's try to use our prompt with the OpenAI client. We expect this to fail because the prompt hasn't been deployed yet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to use the prompt - this should fail because it's not deployed\n",
        "print(\"üß™ Attempting to use the prompt (expecting error)...\")\n",
        "\n",
        "try:\n",
        "    response = chat_with_prompt(\n",
        "        client=openai_client,\n",
        "        prompt_id=PROMPT_ID,\n",
        "        variables={\n",
        "            \"customer_inquiry\": \"My order hasn't arrived yet. What should I do?\"\n",
        "        },\n",
        "        customer_identifier=\"demo_user_123\",\n",
        "        metadata={\"demo\": \"prompt_workflow\"}\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Unexpected success! Response: {response.choices[0].message.content}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Expected error occurred: {str(e)}\")\n",
        "    print(f\"üîç Error type: {type(e).__name__}\")\n",
        "    print(\"\\nüí° This is expected because:\")\n",
        "    print(\"   - The prompt hasn't been deployed yet\")\n",
        "    print(\"   - Prompts need to be deployed before they can be used\")\n",
        "    print(\"   - We'll deploy it in the next step\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Try to Deploy the Prompt (Expected Draft Error)\n",
        "\n",
        "Let's try to deploy our prompt. This might fail if the prompt is still in draft state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to deploy the prompt - this might fail if it's in draft state\n",
        "print(\"üöÄ Attempting to deploy the prompt...\")\n",
        "\n",
        "try:\n",
        "    # Note: This is a conceptual example - actual deployment API might be different\n",
        "    # In practice, you might need to use a specific deployment endpoint\n",
        "    \n",
        "    # For now, let's simulate deployment by trying to get the live version\n",
        "    prompt_details = await client.aget(PROMPT_ID)\n",
        "    print(f\"üìã Prompt details:\")\n",
        "    print(f\"   Name: {prompt_details.name}\")\n",
        "    print(f\"   Versions: {prompt_details.commit_count}\")\n",
        "    print(f\"   Live version: {prompt_details.live_version}\")\n",
        "    \n",
        "    if prompt_details.live_version is None:\n",
        "        print(\"‚ùå No live version found - prompt is not deployed\")\n",
        "        print(\"üí° This is expected because:\")\n",
        "        print(\"   - The prompt version is still in draft state\")\n",
        "        print(\"   - Draft versions cannot be deployed\")\n",
        "        print(\"   - We need to commit the draft first\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Live version found: {prompt_details.live_version}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Deployment error: {str(e)}\")\n",
        "    print(f\"üîç Error type: {type(e).__name__}\")\n",
        "    print(\"\\nüí° This might be expected because:\")\n",
        "    print(\"   - Deployment API might not be available\")\n",
        "    print(\"   - Prompt is in draft state\")\n",
        "    print(\"   - Need to commit draft version first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Commit Draft Version\n",
        "\n",
        "To make a version deployable, we need to commit the current draft. This creates a readonly version that can be deployed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new draft version that commits the current draft into a readonly version\n",
        "print(\"üì¶ Creating a new draft version to commit the current one...\")\n",
        "\n",
        "# This creates version 2, which makes version 1 readonly and deployable\n",
        "version_data_v2 = PromptVersion(\n",
        "    prompt_version_id=\"version-002\",\n",
        "    description=\"Second version - this commits version 1\",\n",
        "    created_at=datetime.now(timezone.utc),\n",
        "    updated_at=datetime.now(timezone.utc),\n",
        "    version=2,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a friendly customer support assistant. Use a warm, professional tone while solving customer problems efficiently.\",\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": \"{{customer_inquiry}}\"},\n",
        "    ],\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.8,  # Slightly higher temperature for more creativity\n",
        "    max_tokens=1800,\n",
        "    top_p=0.95,\n",
        "    frequency_penalty=0.1,\n",
        "    presence_penalty=0.1,\n",
        "    variables={\"customer_inquiry\": \"Customer's question or issue\"},\n",
        "    parent_prompt=PROMPT_ID,\n",
        ")\n",
        "\n",
        "version_v2 = await client.acreate_version(PROMPT_ID, version_data_v2)\n",
        "print(f\"‚úÖ Created version {version_v2.version}\")\n",
        "print(f\"   This should make version {VERSION_1} readonly and deployable\")\n",
        "\n",
        "# Check if version 1 is now readonly\n",
        "version_1_check = await client.aget_version(PROMPT_ID, VERSION_1)\n",
        "print(f\"\\nüîç Version {VERSION_1} status:\")\n",
        "print(f\"   Readonly: {version_1_check.readonly}\")\n",
        "print(f\"   {'‚úÖ Ready for deployment' if version_1_check.readonly else '‚ö†Ô∏è  Still draft'}\")\n",
        "\n",
        "VERSION_2 = version_v2.version\n",
        "print(f\"\\nüîó Version {VERSION_2} created (current draft)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Deploy Successfully\n",
        "\n",
        "Now that we have a committed (readonly) version, let's try to deploy and use it successfully.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now try to use the prompt with OpenAI client\n",
        "print(\"üöÄ Attempting to use the prompt with OpenAI client...\")\n",
        "\n",
        "try:\n",
        "    # Make a call using the standard OpenAI client through Keywords AI gateway\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a professional customer support assistant. Always be helpful, polite, and provide clear solutions to customer problems.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"My order hasn't arrived yet. What should I do?\"\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=2048,\n",
        "        # Keywords AI specific parameters\n",
        "        extra_body={\n",
        "            \"customer_identifier\": \"demo_user_123\",\n",
        "            \"metadata\": {\n",
        "                \"demo\": \"prompt_workflow\",\n",
        "                \"prompt_used\": PROMPT_ID,\n",
        "                \"version_used\": VERSION_1\n",
        "            }\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ Success! Response received:\")\n",
        "    print(f\"üìù Content: {response.choices[0].message.content}\")\n",
        "    print(f\"üîß Model used: {response.model}\")\n",
        "    print(f\"üìä Tokens used: {response.usage.total_tokens if response.usage else 'N/A'}\")\n",
        "    \n",
        "    print(\"\\nüí° What happened:\")\n",
        "    print(\"   - Request went through Keywords AI gateway\")\n",
        "    print(\"   - Used the committed prompt version\")\n",
        "    print(\"   - Got analytics and monitoring\")\n",
        "    print(\"   - Response logged in Keywords AI dashboard\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {str(e)}\")\n",
        "    print(f\"üîç Error type: {type(e).__name__}\")\n",
        "    print(\"\\nüí° If this failed, it might be because:\")\n",
        "    print(\"   - Prompt deployment is not fully implemented yet\")\n",
        "    print(\"   - Need to manually deploy in the UI\")\n",
        "    print(\"   - API endpoint differences\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Iterate - Create a New Version\n",
        "\n",
        "Let's create a new version with different settings to demonstrate iteration and A/B testing capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new version with different approach - more concise and direct\n",
        "print(\"üîß Creating version 3 with a different approach...\")\n",
        "\n",
        "version_data_v3 = PromptVersion(\n",
        "    prompt_version_id=\"version-003\",\n",
        "    description=\"Concise and direct customer support version\",\n",
        "    created_at=datetime.now(timezone.utc),\n",
        "    updated_at=datetime.now(timezone.utc),\n",
        "    version=3,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a concise customer support assistant. Provide direct, actionable solutions quickly. Be helpful but brief.\",\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": \"{{customer_inquiry}}\"},\n",
        "    ],\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.3,  # Lower temperature for more focused responses\n",
        "    max_tokens=1000,  # Shorter responses\n",
        "    top_p=0.8,\n",
        "    frequency_penalty=0.2,\n",
        "    presence_penalty=0.0,\n",
        "    variables={\"customer_inquiry\": \"Customer's question or issue\"},\n",
        "    parent_prompt=PROMPT_ID,\n",
        ")\n",
        "\n",
        "version_v3 = await client.acreate_version(PROMPT_ID, version_data_v3)\n",
        "print(f\"‚úÖ Created version {version_v3.version}\")\n",
        "print(f\"   Model: {version_v3.model}\")\n",
        "print(f\"   Temperature: {version_v3.temperature} (lower for more focused responses)\")\n",
        "print(f\"   Max tokens: {version_v3.max_tokens} (shorter responses)\")\n",
        "\n",
        "# Check version 2 status (should now be readonly)\n",
        "version_2_check = await client.aget_version(PROMPT_ID, VERSION_2)\n",
        "print(f\"\\nüîç Version {VERSION_2} status:\")\n",
        "print(f\"   Readonly: {version_2_check.readonly}\")\n",
        "print(f\"   {'‚úÖ Ready for deployment' if version_2_check.readonly else '‚ö†Ô∏è  Still draft'}\")\n",
        "\n",
        "VERSION_3 = version_v3.version\n",
        "print(f\"\\nüîó Version {VERSION_3} created (current draft)\")\n",
        "\n",
        "# List all versions\n",
        "print(f\"\\nüìã All versions for prompt {PROMPT_ID}:\")\n",
        "versions_list = await client.alist_versions(PROMPT_ID)\n",
        "for v in versions_list.results:\n",
        "    status = \"readonly\" if v.readonly else \"draft\"\n",
        "    print(f\"   - Version {v.version}: {v.description} ({status})\")\n",
        "    print(f\"     Temperature: {v.temperature}, Max tokens: {v.max_tokens}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Deploy New Version\n",
        "\n",
        "Let's test the different versions to see how they perform with the same input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different versions with the same input\n",
        "test_message = \"My order hasn't arrived yet and I need it urgently for a meeting tomorrow. What can you do to help?\"\n",
        "\n",
        "print(\"üß™ Testing different versions with the same input:\")\n",
        "print(f\"üìù Test message: {test_message}\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# Test Version 1 (Professional tone, temp 0.7)\n",
        "print(\"\\nüîç Testing Version 1 (Professional, temp=0.7):\")\n",
        "try:\n",
        "    response_v1 = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a professional customer support assistant. Always be helpful, polite, and provide clear solutions to customer problems.\"\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": test_message}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=2048,\n",
        "        extra_body={\n",
        "            \"customer_identifier\": \"demo_user_123\",\n",
        "            \"metadata\": {\"version_test\": \"v1\", \"demo\": \"comparison\"}\n",
        "        }\n",
        "    )\n",
        "    print(f\"‚úÖ Version 1 Response: {response_v1.choices[0].message.content[:200]}...\")\n",
        "    print(f\"üìä Tokens: {response_v1.usage.total_tokens if response_v1.usage else 'N/A'}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Version 1 Error: {str(e)}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "\n",
        "# Test Version 2 (Friendly tone, temp 0.8) \n",
        "print(\"\\nüîç Testing Version 2 (Friendly, temp=0.8):\")\n",
        "try:\n",
        "    response_v2 = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a friendly customer support assistant. Use a warm, professional tone while solving customer problems efficiently.\"\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": test_message}\n",
        "        ],\n",
        "        temperature=0.8,\n",
        "        max_tokens=1800,\n",
        "        extra_body={\n",
        "            \"customer_identifier\": \"demo_user_123\",\n",
        "            \"metadata\": {\"version_test\": \"v2\", \"demo\": \"comparison\"}\n",
        "        }\n",
        "    )\n",
        "    print(f\"‚úÖ Version 2 Response: {response_v2.choices[0].message.content[:200]}...\")\n",
        "    print(f\"üìä Tokens: {response_v2.usage.total_tokens if response_v2.usage else 'N/A'}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Version 2 Error: {str(e)}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "\n",
        "# Test Version 3 (Concise, temp 0.3)\n",
        "print(\"\\nüîç Testing Version 3 (Concise, temp=0.3):\")\n",
        "try:\n",
        "    response_v3 = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a concise customer support assistant. Provide direct, actionable solutions quickly. Be helpful but brief.\"\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": test_message}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=1000,\n",
        "        extra_body={\n",
        "            \"customer_identifier\": \"demo_user_123\",\n",
        "            \"metadata\": {\"version_test\": \"v3\", \"demo\": \"comparison\"}\n",
        "        }\n",
        "    )\n",
        "    print(f\"‚úÖ Version 3 Response: {response_v3.choices[0].message.content[:200]}...\")\n",
        "    print(f\"üìä Tokens: {response_v3.usage.total_tokens if response_v3.usage else 'N/A'}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Version 3 Error: {str(e)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"\\nüí° Key Observations:\")\n",
        "print(\"   - Different versions produce different response styles\")\n",
        "print(\"   - Temperature affects creativity vs consistency\")\n",
        "print(\"   - Max tokens controls response length\")\n",
        "print(\"   - All requests are logged in Keywords AI for analysis\")\n",
        "print(\"   - You can A/B test different versions in production\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
